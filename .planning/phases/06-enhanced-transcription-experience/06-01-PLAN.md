---
phase: 06-enhanced-transcription-experience
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/services/geminiService.ts
  - src/features/project/hooks/useTranscription.ts
  - src/services/storageService.types.ts
  - src/services/storageService.ts
autonomous: true

must_haves:
  truths:
    - 'AbortController signal cancels both upload and transcription mid-stream'
    - 'AbortError propagates through multi-loop architecture without being caught by retry logic'
    - 'State machine transitions through cancelling -> cancelled states correctly'
    - 'Partial transcript segments are debounce-flushed to localStorage during streaming'
    - 'Progress percentage never jumps backwards (maxProgressSoFar tracking)'
  artifacts:
    - path: 'src/services/geminiService.ts'
      provides: 'AbortSignal-aware uploadFile and generateTranscript'
      contains: 'signal?: AbortSignal'
    - path: 'src/features/project/hooks/useTranscription.ts'
      provides: 'Extended state machine with cancel, partial persistence, and fileUri tracking'
      contains: 'cancelling'
    - path: 'src/services/storageService.types.ts'
      provides: 'Extended ProjectStatus with cancelled state'
      contains: 'cancelled'
    - path: 'src/services/storageService.ts'
      provides: 'Debounced transcript save function and cancelled status validation'
      contains: 'debouncedSaveTranscript'
  key_links:
    - from: 'src/features/project/hooks/useTranscription.ts'
      to: 'src/services/geminiService.ts'
      via: 'AbortController.signal passed to uploadFile and generateTranscript'
      pattern: 'signal.*AbortSignal'
    - from: 'src/features/project/hooks/useTranscription.ts'
      to: 'src/services/storageService.ts'
      via: 'debouncedSaveTranscript called on each PROGRESS event with new segments'
      pattern: 'debouncedSaveTranscript'
    - from: 'src/services/geminiService.ts'
      to: '@google/genai SDK'
      via: 'abortSignal field in GenerateContentConfig'
      pattern: 'abortSignal.*signal'
---

<objective>
Thread AbortController through the transcription pipeline and extend the state machine with cancel/cancelled states, debounced partial persistence, and progress monotonicity.

Purpose: This is the "engine" layer for Phase 6. All downstream UI work (progress display, cancel button, recovery UI) depends on these service-level capabilities existing first.

Output: Modified geminiService with AbortSignal support, extended useTranscription hook with cancel/resume/partial persistence, extended storage types with 'cancelled' status.
</objective>

<execution_context>
@/Users/david.cogan@postman.com/.claude/get-shit-done/workflows/execute-plan.md
@/Users/david.cogan@postman.com/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/06-enhanced-transcription-experience/06-CONTEXT.md
@.planning/phases/06-enhanced-transcription-experience/06-RESEARCH.md
@src/services/geminiService.ts
@src/features/project/hooks/useTranscription.ts
@src/services/storageService.types.ts
@src/services/storageService.ts
@src/types/index.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: AbortController threading through geminiService</name>
  <files>src/services/geminiService.ts</files>
  <action>
Add `signal?: AbortSignal` parameter to both `uploadFile` and `generateTranscript` functions.

**uploadFile changes:**

- Add `signal?: AbortSignal` as the 4th parameter
- Pass `signal` to every `fetch()` call (the initial POST to `/api/gemini-upload` and every PUT to `/proxy-upload` in the chunk loop)
- Check `signal?.aborted` before each chunk iteration in the while loop

**generateTranscript changes:**

- Add `signal?: AbortSignal` as the 6th parameter (after `onProgress`)
- Check `signal?.aborted` at the top of the while loop (before each iteration). If aborted, throw `new DOMException('Transcription cancelled', 'AbortError')`
- Pass `signal` to the SDK call: add `abortSignal: signal` to the `config` object in `aiClient.models.generateContentStream()`
- Check `signal?.aborted` inside the `for await (const chunk of stream)` loop. If aborted, throw `new DOMException('Transcription cancelled', 'AbortError')`
- **CRITICAL: In the inner catch block** (`catch (innerError)` on ~line 340), add AbortError detection BEFORE the existing retry logic:
  ```
  if (innerError instanceof DOMException && innerError.name === 'AbortError') {
    throw innerError; // Propagate cancellation, never retry
  }
  ```
  This prevents the retry mechanism from swallowing cancellation signals.

**Progress monotonicity:**

- Add a `let maxProgress = 0` variable before the while loop
- In the progress calculation (~line 262-270), wrap the result: `const percentage = Math.max(maxProgress, calculatedPercentage)` then `maxProgress = percentage`
- This prevents the progress bar from jumping backwards between loop iterations

Do NOT change the function signatures in any other way. Do NOT remove or alter the existing retry logic, deduplication logic, or loop control logic. Work carefully around the multi-loop architecture.
</action>
<verify>
Run `npx tsc --noEmit` to confirm no type errors. Verify that:

1. Both functions accept an optional `signal` parameter
2. AbortError is explicitly re-thrown in the inner catch block
3. `abortSignal: signal` is in the SDK config object
4. `signal` is passed to all `fetch()` calls
5. `maxProgress` tracking wraps the percentage calculation
   </verify>
   <done>
   uploadFile and generateTranscript accept AbortSignal, propagate it to fetch/SDK, check it at loop boundaries, and AbortError bypasses retry logic. Progress never decreases.
   </done>
   </task>

<task type="auto">
  <name>Task 2: State machine extension and partial persistence in useTranscription</name>
  <files>
src/features/project/hooks/useTranscription.ts
src/services/storageService.types.ts
src/services/storageService.ts
  </files>
  <action>
**storageService.types.ts changes:**
- Add `'cancelled'` to the `ProjectStatus` union type (after `'error'`)
- Add optional `fileUri?: string` field to `TranscriptData` interface (for resume-without-re-upload when fileUri is still valid within 48h)

**storageService.ts changes:**

- Add `'cancelled'` to the `VALID_PROJECT_STATUSES` Set
- Add a new exported function `debouncedSaveTranscript(data: TranscriptData): void` that:
  - Serializes the TranscriptData to JSON
  - Calls the existing private `debouncedWrite(STORAGE_KEYS.transcript(data.projectId), serialized)` function
  - Also queues a debounced update of the project metadata's segmentCount by reading current projects, finding the matching project, and updating segmentCount to data.segments.length, then calling `debouncedWrite(STORAGE_KEYS.PROJECTS, ...)`
  - This reuses the existing 300ms debounce infrastructure

**useTranscription.ts changes:**

1. **Extend TranscriptionState:** Add `'cancelling'` and `'cancelled'` to the union type

2. **Extend TranscriptionEvent:** Add:
   - `{ type: 'CANCEL' }`
   - `{ type: 'CANCELLED'; segments: TranscriptSegment[] }`
   - `{ type: 'RESUME' }`

3. **Extend TRANSITIONS map:**

   ```
   uploading: { ...existing, CANCEL: 'cancelling' },
   processing: { ...existing, CANCEL: 'cancelling' },
   cancelling: { CANCELLED: 'cancelled', ERROR: 'error' },
   cancelled: { RESET: 'idle', RESUME: 'uploading' },
   ```

4. **Extend TranscriptionMachineState:** Add:
   - `fileUri: string | null` (persists the uploaded file URI for resume)
   - `staleSegments: TranscriptSegment[]` (old partial segments shown dimmed during re-transcription)

5. **Extend initialState:** Add `fileUri: null`, `staleSegments: []`

6. **Extend reducer cases:**
   - `START`: reset staleSegments to `[]`, keep fileUri if resuming (check if event has a `fromResume` flag -- actually, the RESUME event will handle this)
   - `UPLOAD_COMPLETE`: update fileUri if available (add fileUri to the UPLOAD_COMPLETE event type)
   - `CANCEL`: set state to 'cancelling' (no other changes -- cancellation is handled in startTranscription)
   - `CANCELLED`: set state to 'cancelled', set transcript to event.segments (the partial segments saved so far)
   - `RESUME`: set state to 'uploading', move current transcript to staleSegments, reset progress to 0
   - `PROGRESS`: also accumulate segment into transcript array (not just currentSegment). If `event.segment` is not null, push it onto `current.transcript`

7. **Update UPLOAD_COMPLETE event type** to include `fileUri: string`

8. **Add AbortController management:**
   - Add `const abortControllerRef = useRef<AbortController | null>(null)` at the top of the hook
   - In `startTranscription`: create new `AbortController()`, store in ref. Pass `abortControllerRef.current.signal` to both `uploadFile` and `generateTranscript`
   - Update the uploadFile call to pass the fileUri back: `dispatch({ type: 'UPLOAD_COMPLETE', fileUri })`

9. **Add cancel function:**

   ```typescript
   const cancel = useCallback(() => {
     if (abortControllerRef.current) {
       dispatch({ type: 'CANCEL' });
       abortControllerRef.current.abort();
     }
   }, []);
   ```

10. **Handle AbortError in startTranscription catch block:**
    - Check if `err instanceof DOMException && err.name === 'AbortError'`
    - If so, dispatch `{ type: 'CANCELLED', segments: machineState.transcript }` instead of ERROR
    - Note: use a local `accumulatedSegments` array to track segments (since machineState may be stale in the closure). Pass this to CANCELLED.

11. **Add partial persistence in the progress callback:**
    - Import `debouncedSaveTranscript` and `flushPendingWrites` from storageService
    - The `onProgress` callback passed to `generateTranscript` should call `debouncedSaveTranscript({ projectId, segments: accumulatedSegments, completedAt: null, fileUri })` when segments accumulate
    - `projectId` needs to be passed as a new parameter to `startTranscription` (4th parameter): `startTranscription(file, mimeType, duration, projectId)`
    - On cancellation, call `flushPendingWrites()` to ensure partial data is persisted immediately

12. **Update UseTranscriptionReturn interface:**
    - Add `cancel: () => void`
    - Update `startTranscription` signature to include `projectId: string` as 4th parameter

13. **Add resume function:**
    ```typescript
    const resume = useCallback(
      async (
        file: File,
        mimeType: string,
        duration: number,
        projectId: string
      ) => {
        dispatch({ type: 'RESUME' });
        // Then call the same startTranscription logic
        // but skip upload if fileUri is available
        await startTranscription(file, mimeType, duration, projectId);
      },
      [startTranscription]
    );
    ```
    Actually, simplify: resume just dispatches RESUME (which moves transcript to staleSegments) then calls startTranscription. The caller handles providing the file.

Return `cancel` and `resume` from the hook alongside existing returns.
</action>
<verify>
Run `npx tsc --noEmit` to confirm no type errors. Verify:

1. `'cancelled'` is in ProjectStatus union and VALID_PROJECT_STATUSES
2. `debouncedSaveTranscript` is exported from storageService
3. `cancel` and `resume` are returned from useTranscription
4. TRANSITIONS map includes cancelling and cancelled states
5. AbortError handling dispatches CANCELLED, not ERROR
6. PROGRESS events accumulate segments into transcript array
7. fileUri is tracked through the state machine
   </verify>
   <done>
   State machine has cancelling/cancelled states, AbortController is managed in useRef, partial segments are debounce-flushed to localStorage during streaming, fileUri is persisted for recovery, and cancel/resume functions are exposed from the hook.
   </done>
   </task>

</tasks>

<verification>
1. `npx tsc --noEmit` passes with zero errors
2. `npx eslint src/services/geminiService.ts src/features/project/hooks/useTranscription.ts src/services/storageService.ts src/services/storageService.types.ts` passes
3. The TRANSITIONS map prevents invalid state transitions (e.g., cancelling -> completed is not possible)
4. AbortError is never caught by retry logic in generateTranscript
5. debouncedSaveTranscript uses the existing debounce infrastructure (not a new timer)
</verification>

<success_criteria>

- geminiService.uploadFile and generateTranscript accept optional AbortSignal
- AbortSignal is passed to fetch() calls and SDK config.abortSignal
- AbortError bypasses retry logic with explicit re-throw
- useTranscription state machine includes cancelling and cancelled states
- cancel() aborts the controller and transitions to cancelling
- Partial segments are debounce-flushed to localStorage during streaming
- Progress bar value never decreases (maxProgress tracking)
- ProjectStatus type includes 'cancelled'
- fileUri is tracked in state for resume-without-re-upload
  </success_criteria>

<output>
After completion, create `.planning/phases/06-enhanced-transcription-experience/06-01-SUMMARY.md`
</output>
